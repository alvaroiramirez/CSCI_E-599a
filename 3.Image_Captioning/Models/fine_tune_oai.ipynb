{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY5SVd97ImVO",
        "outputId": "6c6df4ca-0716-47c8-862a-ce662bbbeded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.70.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4px0gnwx-zfV"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_API_KEY = 'KEY HERE'\n",
        "\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpw2ni7DKz8B",
        "outputId": "bccbab1e-dfde-481b-cf4f-9ab810acdec9"
      },
      "outputs": [],
      "source": [
        "#upload the JSONL file\n",
        "with open(\"JSONL FILE PATH HERE\", \"rb\") as file:\n",
        "    training_file = client.files.create(\n",
        "        file=file,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "\n",
        "print(f\"File uploaded with ID: {training_file.id}\")\n",
        "\n",
        "#create and start the fine-tuning job\n",
        "job = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    model=\"gpt-4o-2024-08-06\"  #base model to use\n",
        ")\n",
        "\n",
        "print(f\"Fine-tuning job created: {job.id}\")\n",
        "\n",
        "#status of your fine-tuning job\n",
        "job_status = client.fine_tuning.jobs.retrieve(job.id)\n",
        "print(f\"Status: {job_status.status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eEtqR61K7Ed",
        "outputId": "3008a97e-91f6-4b98-a00d-3433e2391369"
      },
      "outputs": [],
      "source": [
        "job_status = client.fine_tuning.jobs.retrieve(\"JOB ID HERE\")\n",
        "print(f\"Status: {job_status.status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Izs5qtA-cOY",
        "outputId": "6c7e4ac0-4291-4299-add6-090b5aa485ae"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import base64\n",
        "\n",
        "def encode_image_to_base64(image_path):\n",
        "\n",
        "    \"\"\"Convert an image file to base64 encoding.\"\"\"\n",
        "\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "def generate_caption_for_image(image_path, model_id):\n",
        "\n",
        "    \"\"\"Generate a caption for an image using a fine-tuned model.\"\"\"\n",
        "\n",
        "    #encode the image\n",
        "    base64_image = encode_image_to_base64(image_path)\n",
        "\n",
        "    #create the API request\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_id,  #fine-tuned model id\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are trained to caption images.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"Caption this image.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpg;base64,{base64_image}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    #generated caption\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "image_path = \"TEST IMAGE HERE\"\n",
        "model_id = \"MODEL ID HERE\"\n",
        "\n",
        "caption = generate_caption_for_image(image_path, model_id)\n",
        "print(f\"Generated caption: {caption}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
